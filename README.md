# adversarial-example(classify)
[Foolbox implementation](https://foolbox.readthedocs.io/en/latest/index.html)    
## Gradient-based attacks                           
|year/month   | method  |                                           paper                                 |                 
|:-----------:|:-------:|:-------------------------------------------------------------------------------:|     
|2013-12      |L-BFGS   | [Intriguing properties of neural networks](https://arxiv.org/pdf/1312.6199.pdf)    
|2014-12      |FGSM     | [Explaining and Harnessing Adversarial Examples](https://arxiv.org/abs/1412.6572)        
|2015-10      |L-BFGS-B | [Exploring the Space of Adversarial Images](https://arxiv.org/abs/1510.05328)
|2015-11      |DeepFool | [DeepFool: a simple and accurate method to fool deep neural networks](https://arxiv.org/abs/1511.04599)    
|2015-11      |JSMA     | [The Limitations of Deep Learning in Adversarial Settings](https://arxiv.org/abs/1511.07528)
|2016-07      |PGD   | [Adversarial examples in the physical world](https://arxiv.org/abs/1607.02533)
|2016-08      |C&W   | [Towards Evaluating the Robustness of Neural Networks](https://arxiv.org/abs/1608.04644)
|2017-06      |BIM   | [Towards Deep Learning Models Resistant to Adversarial Attacks](https://arxiv.org/abs/1706.06083)
|2017-09      |EADAttack   | [EAD: Elastic-Net Attacks to Deep Neural Networks via Adversarial Examples](https://arxiv.org/abs/1709.04114)
|2017-10      |MomentumIterativeAttack   | [Boosting Adversarial Attacks with Momentum](https://arxiv.org/abs/1710.06081)
|2017-12      |NewtonFoolAttack   | [Objective Metrics and Gradient Descent Algorithms for Adversarial Examples in Machine Learning](https://andrewxiwu.github.io/public/papers/2017/JWJ17-objective-metrics-and-gradient-descent-based-algorithms-for-adversarial-examples-in-machine-learning.pdf)
|2018-04      |ADefAttack   | [ADef: an Iterative Algorithm to Construct Adversarial Deformations](https://arxiv.org/abs/1804.07729)
|2018-11      |DecoupledDirectionNormL2Attack   | [Decoupling Direction and Norm for Efficient Gradient-Based L2 Adversarial Attacks and Defenses](https://arxiv.org/abs/1811.09600)
|2018-11      |SparseFoolAttack   | [SparseFool: a few pixels make a big difference](https://arxiv.org/abs/1811.02248)

## Score-based attacks                  
|year/month   | method  |                                           paper                                 |                 
|:-----------:|:-------:|:-------------------------------------------------------------------------------:|                      
|2016-12      |LocalSearchAttack     | [Simple Black-Box Adversarial Perturbations for Deep Networks](https://arxiv.org/abs/1612.06299) 

## Decision-based attacks          
|year/month   | method  |                                           paper                                 |                 
|:-----------:|:-------:|:-------------------------------------------------------------------------------:|                    
|2017-12      |SpatialAttack     | [A Rotation and a Translation Suffice: Fooling CNNs with Simple Transformations](https://arxiv.org/abs/1712.02779)  
|2017-12      |BoundaryAttack     | [Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models](https://arxiv.org/abs/1712.04248)  
|2018-05      |PointwiseAttack     | [Towards the first adversarially robust neural network model on MNIST](https://arxiv.org/abs/1805.09190)  
                                  
                             
                          
# adversarial-example(detection)
|year/month   | method  |                                           paper                                 |      code     |             
|:-----------:|:-------:|:-------------------------------------------------------------------------------:|:-------------:|             
|2017-03      |DAG| [Adversarial Examples for Semantic Segmentation and Object Detection](https://arxiv.org/abs/1703.08603)|[DAG](https://github.com/cihangxie/DAG)|  
|2018-07      |RP2      | [Physical Adversarial Examples for Object Detectors](https://arxiv.org/abs/1807.07769)| None        |                   
|2018-09      |RAP      | [Robust Adversarial Perturbation on Deep Proposal-based Models](https://arxiv.org/abs/1809.05962)| None  |                  
|2018-11      |UEA      | [Transferable Adversarial Attacks for Image and Video Object Detection](https://arxiv.org/abs/1811.12641) |[UEA](https://github.com/LiangSiyuan21/Adversarial-Attacks-for-Image-and-Video-Object-Detection)|                 

